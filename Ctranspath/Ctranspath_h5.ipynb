{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de68150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from ctran import ctranspath   # Make sure ctranspath.py is in the same directory or in sys.path\n",
    "\n",
    "# ============================\n",
    "# 1️⃣ Paths configuration\n",
    "#    All cancer-type folders are under root_dir\n",
    "# ============================\n",
    "root_dir = r\"F:\\patches_n\"          # Root directory containing patch folders (one folder per cancer type)\n",
    "output_root = os.getcwd()           # Output directory for h5 files (current working directory)\n",
    "model_path = r\"./ctranspath.pth\"    # Path to pretrained CTransPath model\n",
    "                                   # (recommended to exclude from GitHub via .gitignore)\n",
    "\n",
    "# ============================\n",
    "# 2️⃣ Image preprocessing\n",
    "#    Resize to fixed 224x224 for ViT/CTransPath\n",
    "# ============================\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   # Fixed size input\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "# ============================\n",
    "# 3️⃣ Dataset definition\n",
    "#    Includes basic error handling for corrupted images\n",
    "# ============================\n",
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, file_list):\n",
    "        self.file_list = file_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_list[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            image = transform(image)\n",
    "            return image, img_path\n",
    "        except Exception:\n",
    "            # If image loading fails, return None (will be filtered later)\n",
    "            return None, img_path\n",
    "\n",
    "\n",
    "def collate_skip_none(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function for DataLoader:\n",
    "    - Filters out samples where image is None (corrupted images)\n",
    "    - Returns (None, None) if the entire batch is invalid\n",
    "    \"\"\"\n",
    "    batch = [b for b in batch if b[0] is not None]\n",
    "    if len(batch) == 0:\n",
    "        return None, None\n",
    "    images, paths = zip(*batch)\n",
    "    return torch.stack(images, dim=0), list(paths)\n",
    "\n",
    "# ============================\n",
    "# 4️⃣ Load pretrained model\n",
    "#    Compatible with checkpoints storing either:\n",
    "#    - {\"model\": state_dict}\n",
    "#    - state_dict directly\n",
    "# ============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == \"cuda\":\n",
    "    torch.backends.cudnn.benchmark = True  # Speed up for fixed input size\n",
    "\n",
    "model = ctranspath()\n",
    "model.head = nn.Identity()   # Remove classification head, output 768-dim features\n",
    "\n",
    "ckpt = torch.load(model_path, map_location=device)\n",
    "state = ckpt[\"model\"] if isinstance(ckpt, dict) and \"model\" in ckpt else ckpt\n",
    "model.load_state_dict(state, strict=True)\n",
    "model.to(device).eval()\n",
    "\n",
    "# ============================\n",
    "# 5️⃣ Iterate over cancer-type folders\n",
    "# ============================\n",
    "cancer_types = [\n",
    "    d for d in os.listdir(root_dir)\n",
    "    if os.path.isdir(os.path.join(root_dir, d))\n",
    "]\n",
    "cancer_types = [d for d in cancer_types if d.upper() != \"TUM\"]  # Exclude TUM folder\n",
    "print(f\"Detected cancer types: {cancer_types}\")\n",
    "\n",
    "for cancer in cancer_types:\n",
    "    patch_dir = os.path.join(root_dir, cancer)\n",
    "\n",
    "    # Output directory for this cancer type\n",
    "    save_dir = os.path.join(output_root, cancer)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"\\n==== Processing cancer type: {cancer} ====\")\n",
    "\n",
    "    # Collect all patch images\n",
    "    all_patches = [\n",
    "        os.path.join(patch_dir, f)\n",
    "        for f in os.listdir(patch_dir)\n",
    "        if f.lower().endswith(\".jpg\")\n",
    "    ]\n",
    "\n",
    "    # ============================\n",
    "    # Group patches by WSI ID\n",
    "    # Use os.path.splitext to avoid errors when filenames contain multiple dots\n",
    "    # ============================\n",
    "    wsi_dict = {}\n",
    "    for patch_path in all_patches:\n",
    "        wsi_id = os.path.splitext(os.path.basename(patch_path))[0]\n",
    "        wsi_dict.setdefault(wsi_id, []).append(patch_path)\n",
    "\n",
    "    print(f\"Found {len(wsi_dict)} WSIs with {len(all_patches)} patches in total\")\n",
    "\n",
    "    # ============================\n",
    "    # 6️⃣ Feature extraction and H5 saving\n",
    "    # ============================\n",
    "    for wsi_id, patch_list in wsi_dict.items():\n",
    "        save_path = os.path.join(save_dir, f\"{wsi_id}.h5\")\n",
    "\n",
    "        # Resume support: skip if already exists\n",
    "        if os.path.exists(save_path):\n",
    "            print(f\"⏩ Skip {wsi_id} (already exists)\")\n",
    "            continue\n",
    "\n",
    "        print(f\"▶ Processing WSI: {wsi_id} (patch count: {len(patch_list)})\")\n",
    "\n",
    "        dataset = PatchDataset(patch_list)\n",
    "        loader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=16,\n",
    "            shuffle=False,\n",
    "            num_workers=0,              # Safer for Jupyter; increase when running as script\n",
    "            collate_fn=collate_skip_none\n",
    "        )\n",
    "\n",
    "        all_features = []\n",
    "        valid_patch_list = []  # Patch names aligned with extracted features\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, paths in loader:\n",
    "                if images is None:\n",
    "                    continue\n",
    "                images = images.to(device)\n",
    "                feats = model(images)           # Shape: (B, 768)\n",
    "                feats = feats.cpu().numpy()\n",
    "                all_features.append(feats)\n",
    "                valid_patch_list.extend(paths)\n",
    "\n",
    "        if len(all_features) == 0:\n",
    "            print(f\"⚠️ No valid patches for {wsi_id}, skip saving\")\n",
    "            continue\n",
    "\n",
    "        all_features = np.concatenate(all_features, axis=0)  # (N, 768)\n",
    "\n",
    "        # Save to HDF5\n",
    "        with h5py.File(save_path, \"w\") as h5f:\n",
    "            h5f.create_dataset(\"features\", data=all_features)\n",
    "\n",
    "            # Use UTF-8 string dtype for better compatibility\n",
    "            dt = h5py.string_dtype(encoding=\"utf-8\")\n",
    "            h5f.create_dataset(\n",
    "                \"patch_names\",\n",
    "                data=np.array(valid_patch_list, dtype=object),\n",
    "                dtype=dt\n",
    "            )\n",
    "\n",
    "        print(f\"✅ Saved {wsi_id} to {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
